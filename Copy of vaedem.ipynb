{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of vaedem.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"XRpH3dYm7BQh","colab_type":"code","outputId":"70f769e1-6580-4908-ceb6-b29211ee953f","executionInfo":{"status":"ok","timestamp":1574114184013,"user_tz":0,"elapsed":80557,"user":{"displayName":"Stefan Brugger","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANFCBfedBoHUWqNZvsqCls5RVp-zxycAOvMjpyZos=s64","userId":"09745208683004655373"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jXCXji51Nwix","colab_type":"code","colab":{}},"source":["import math \n","import numpy as np\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.nn import ModuleList, ParameterList, Parameter\n","from torch.autograd import Variable, Function\n","from torch.nn import Linear, Module, LSTM, Parameter, BatchNorm2d, Conv2d, ConvTranspose2d, Softmax, RNN, RNNBase, RNNCell, RNNCellBase\n","from torch import zeros,zeros_like, ones_like, cat, ByteTensor, FloatTensor, rand, log, sigmoid, ones\n","from torch import add,tanh,squeeze,Tensor,float,stack, argmax\n","from torch import max as torchmax\n","from torch import min as torchmin\n","from torch.autograd import Variable\n","from torch import cuda, no_grad, save, load, cat, zeros\n","from torch.optim import Adam\n","import torch \n","\n","class trainer(object):\n","\tdef __init__(self,p,model):\n","\t\tself.p = p\n","\t\tself.model = model\n","\t\tself.optimizer = Adam(self.model.parameters(), lr=self.model.p['lr'], weight_decay=1e-5)\n","\n","# thi is what you would build\n","class pc_conv_network(Module):\n","\tdef __init__(self,p):\n","\t\tsuper(pc_conv_network, self).__init__()\n","\n","\t\t# # will want to increase receptive field size as ascend\n","\t\t# for i in range(p['layers']):\n","\t\t# \tpc1 = pc_conv_layer(p['batch_size'], p['chan'][2], p['chan'][1], p['imdim'][2], p['nf'][2], 1, 0.0005)\n","\t\t# \tpc2 = pc_conv_layer(p['batch_size'], p['chan'][3], p['chan'][2], p['imdim'][3], p['nf'][3], 1, 0.0005)\n","\t\t# who knows if need batch norm\n","\t\tself.bs = p['bs']\n","\t\tself.iter = p['iter']\n","\t\tself.nlayers = p['layers']\n","\t\tself.chan = p['chan']\n","\t\tself.imdim = p['imdim']\n","\t\tself.imchan = p['imchan']\n","\n","\t\tself.F = None\n","\t\tself.F_last = None\n","\n","\t\tself.baseline = None\n","\n","\t\tself.conv_trans = ModuleList(\n","\t\t\t[ConvTranspose2d(p['chan'][i+1], p['chan'][i], p['ks'][i], 1,p['pad'][i])\n","\t\t\tfor i in range(self.nlayers)])\n","\n","\t\t# phi \n","\t\t# phi = 0 uses -1 (image), 0 and 1\n","\t\t# phi = 2 uses 1, 2 and 3\n","\t\tphi = []\n","\t\tfor i in range(self.nlayers):\n","\t\t\tphi.append(nn.Parameter(torch.rand(p['bs'],self.chan[i+1] * self.imdim[i] * self.imdim[i] )))\n","\t\t#phi.append(nn.Parameter(torch.ones(p['bs'],self.chan[self.nlayers] * self.imdim[self.nlayers]^2)))\n","\t\tself.phi = nn.ParameterList(phi)\n","\t\tself.top_cause = torch.ones_like(phi[self.nlayers-1])\n","\n","\t\t# should be one Sigma matrix over whole batch ***\n","\t\tself.Sigma = nn.ParameterList([nn.Parameter(torch.diag(torch.ones(self.chan[i+1] * self.imdim[i+1] * self.imdim[i+1])))\n","\t\t\t for i in range(-1,self.nlayers)])\n","\n","\t\tself.optimizer = Adam(self.parameters(), lr=p['lr'], weight_decay=1e-5)\n","\n","\tdef loss(self, i):\n","\n","\t\t\n","\t\tself.F = 0\n","\n","\t\tTheta__h_of_phi = (self.conv_trans[i](F.relu(self.phi[i].view(self.bs, self.chan[i+1], self.imdim[i+1], self.imdim[i+1])))).view(self.bs,-1)\n","\n","\t\tif i == self.nlayers-1:\n","\t\t\tTheta__h_of_phi_above = self.top_cause\n","\n","\t\telse:\n","\t\t\tTheta__h_of_phi_above = (self.conv_trans[i+1](F.relu(self.phi[i+1].view(self.bs, self.chan[i+2], self.imdim[i+2], self.imdim[i+2])))).view(self.bs,-1)\n","\t \n","\t\tif i > 0:\n","\n","\t\t\tself.F += - torch.sum(0.5*(\n","\t\t\t\t- torch.logdet(self.Sigma[i+1])\n","\t\t\t\t- torch.squeeze(torch.matmul(torch.matmul(\n","\t\t\t\t\t(self.phi[i] - Theta__h_of_phi_above).unsqueeze(1),\n","\t\t\t\t\ttorch.inverse(self.Sigma[i+1])),\n","\t\t\t\t(self.phi[i] - Theta__h_of_phi_above).unsqueeze(2)))\n","\n","\t\t\t\t- torch.logdet(self.Sigma[i]) \n","\t\t\t\t- torch.squeeze(torch.matmul(torch.matmul(\n","\t\t\t\t\t(self.phi[i-1] - Theta__h_of_phi).unsqueeze(1),   \n","\t\t\t\t\ttorch.inverse(self.Sigma[i])),\t\n","\t\t\t\t(self.phi[i-1] - Theta__h_of_phi).unsqueeze(2)))\n","\t\t\t\t))\n","\t\tif i == 0:\n","\t\t\tself.F += - torch.sum(0.5*(\t # minus here so treated as loss\n","\t\t\t\t- torch.logdet(self.Sigma[i+1])\n","\t\t\t\t- torch.squeeze(torch.matmul(torch.matmul(\n","\t\t\t\t\t(self.phi[i] - Theta__h_of_phi_above).unsqueeze(1), \n","\t\t\t\t\ttorch.inverse(self.Sigma[i+1])),\n","\t\t\t\t(self.phi[i] - Theta__h_of_phi_above).unsqueeze(2)))\n","\n","\t\t\t\t- torch.logdet(self.Sigma[i]) \n","\t\t\t\t- torch.squeeze(torch.matmul(\n","\t\t\t\t\ttorch.matmul((self.images - Theta__h_of_phi).unsqueeze(1),   \n","\t\t\t\t\ttorch.inverse(self.Sigma[i])),\n","\t\t\t\t(self.images - Theta__h_of_phi).unsqueeze(2)))\n","\t\t\t\t))\n","\t\tif i == 0:\n","\t\t\tself.estimate = Theta__h_of_phi\n","\n","\t\t\n","\n","\tdef inference(self, i):\n","\n","\t\tself.conv_trans.requires_grad_(False)\n","\t\tself.Sigma.requires_grad_(False)\n","\t\tself.phi.requires_grad_(True)\n","\n","\t\tself.optimizer.zero_grad()\n","\t\tself.loss(i)\n","\t\tself.F.backward()\n","\t\tself.optimizer.step()\n","\n","\tdef learn(self,i):\n","\n","\t\tself.conv_trans.requires_grad_(True)\n","\t\tself.Sigma.requires_grad_(True)\n","\t\tself.phi.requires_grad_(False)\n","\n","\t\tself.optimizer.zero_grad()\n","\t\tself.loss(i)\n","\t\tself.F.backward()\n","\t\tself.optimizer.step()\n","\n","\n","\tdef forward(self, images, learn=0):\n","\t\tself.F_last = self.F\n","\t\tself.images = images.view(self.bs, -1)\n","\t\tfor n in range(self.iter):\n","\t\t\tprint(n)\n","\t\t\tif self.F is not None:\n","\t\t\t\tself.F_last = self.F\n","\t\t\tfor i in range(self.nlayers):\n","\t\t\t\tself.inference(i)\n","\n","\t\t\t\n","\t\t\tprint(self.F)\n","\t\t\tprint(torch.sum(self.images-self.estimate))\n","\t\t\tif self.F_last is not None:\n","\t\t\t\tprint(self.F - self.F_last)\n","\t\t\t\tif self.F > self.F_last:\n","\t\t\t\t\t#self.optimizer = Adam(self.parameters(), lr=p['lr']/5, weight_decay=1e-5)\n","\t\t\t\t\tbreak\n","\t\tif learn:\n","\t\t\tfor i in range(self.nlayers):\n","\t\t\t\tself.optimizer = Adam(self.parameters(), lr=0.001, weight_decay=1e-5)\n","\t\t\t\tself.learn(i)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_7cFIQ2Q3EN","colab_type":"code","colab":{}},"source":["p = dict()\n","p['layers'] = 3\n","p['chan'] = dict()\n","p['imchan'] = 1\n","p['chan'][0] = 1\n","p['chan'][1] = 4\n","p['chan'][2] = 8\n","p['chan'][3] = 16\n","\n","p['pad'] = dict()\n","p['pad'][0] = 1\n","p['pad'][1] = 1\n","p['pad'][2] = 1\n","p['pad'][3] = 1\n","\n","p['ks'] = dict()\n","p['ks'][0] = 5\n","p['ks'][1] = 5\n","p['ks'][2] = 9\n","\n","p['iter'] = 200\n","p['bs'] = 200\n","# image size - can prob be done automatically\n","p['imdim'] = dict()\n","p['imdim'][0] = 21\n","p['imdim'][1] = 21\n","p['imdim'][2] = 21\n","p['imdim'][3] = 21\n","p['pad'] = dict()\n","p['pad'][0] = 2\n","p['pad'][1] = 2\n","p['pad'][2] = 4\n","\n","p['lr'] = 0.05\n","a = pc_conv_network(p)\n","#batch_size, number_of_kernels, w, h].\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJ6CEsEGtCMY","colab_type":"code","outputId":"5fcb9c46-da06-48c3-a5f9-5fda3466a9ef","executionInfo":{"status":"ok","timestamp":1583401598746,"user_tz":0,"elapsed":837257,"user":{"displayName":"Stefan Brugger","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2hD3BccYoCZ1sg2Zmk5k0vgGm225f9Eq4B84cz1o=s64","userId":"09745208683004655373"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["a = pc_conv_network(p)\n","pred = torch.rand(p['bs'],p['chan'][0]*p['imdim'][0],p['imdim'][0])\n","#p['lr'] = 0.04\n","F= a(pred, learn =1)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n","tensor(378844.5625, grad_fn=<AddBackward0>)\n","tensor(38188.3750, grad_fn=<SumBackward0>)\n","1\n","tensor(299320.3438, grad_fn=<AddBackward0>)\n","tensor(36080.9062, grad_fn=<SumBackward0>)\n","tensor(-79524.2188, grad_fn=<SubBackward0>)\n","2\n","tensor(253078.2188, grad_fn=<AddBackward0>)\n","tensor(35138.4258, grad_fn=<SumBackward0>)\n","tensor(-46242.1250, grad_fn=<SubBackward0>)\n","3\n","tensor(220760.5312, grad_fn=<AddBackward0>)\n","tensor(34450.3594, grad_fn=<SumBackward0>)\n","tensor(-32317.6875, grad_fn=<SubBackward0>)\n","4\n","tensor(192178.8750, grad_fn=<AddBackward0>)\n","tensor(33745.4688, grad_fn=<SumBackward0>)\n","tensor(-28581.6562, grad_fn=<SubBackward0>)\n","5\n","tensor(164317., grad_fn=<AddBackward0>)\n","tensor(32858., grad_fn=<SumBackward0>)\n","tensor(-27861.8750, grad_fn=<SubBackward0>)\n","6\n","tensor(137731.4219, grad_fn=<AddBackward0>)\n","tensor(31699.7500, grad_fn=<SumBackward0>)\n","tensor(-26585.5781, grad_fn=<SubBackward0>)\n","7\n","tensor(113702.5703, grad_fn=<AddBackward0>)\n","tensor(30280.6816, grad_fn=<SumBackward0>)\n","tensor(-24028.8516, grad_fn=<SubBackward0>)\n","8\n","tensor(92987.4531, grad_fn=<AddBackward0>)\n","tensor(28669.8711, grad_fn=<SumBackward0>)\n","tensor(-20715.1172, grad_fn=<SubBackward0>)\n","9\n","tensor(75681.9453, grad_fn=<AddBackward0>)\n","tensor(26977.0703, grad_fn=<SumBackward0>)\n","tensor(-17305.5078, grad_fn=<SubBackward0>)\n","10\n","tensor(61492.7773, grad_fn=<AddBackward0>)\n","tensor(25338.6836, grad_fn=<SumBackward0>)\n","tensor(-14189.1680, grad_fn=<SubBackward0>)\n","11\n","tensor(49992.2852, grad_fn=<AddBackward0>)\n","tensor(23848.8633, grad_fn=<SumBackward0>)\n","tensor(-11500.4922, grad_fn=<SubBackward0>)\n","12\n","tensor(40743.7969, grad_fn=<AddBackward0>)\n","tensor(22562.1641, grad_fn=<SumBackward0>)\n","tensor(-9248.4883, grad_fn=<SubBackward0>)\n","13\n","tensor(33339.5039, grad_fn=<AddBackward0>)\n","tensor(21514.0195, grad_fn=<SumBackward0>)\n","tensor(-7404.2930, grad_fn=<SubBackward0>)\n","14\n","tensor(27410.3574, grad_fn=<AddBackward0>)\n","tensor(20695.9102, grad_fn=<SumBackward0>)\n","tensor(-5929.1465, grad_fn=<SubBackward0>)\n","15\n","tensor(22634.4492, grad_fn=<AddBackward0>)\n","tensor(20064.0625, grad_fn=<SumBackward0>)\n","tensor(-4775.9082, grad_fn=<SubBackward0>)\n","16\n","tensor(18747.2227, grad_fn=<AddBackward0>)\n","tensor(19562.4668, grad_fn=<SumBackward0>)\n","tensor(-3887.2266, grad_fn=<SubBackward0>)\n","17\n","tensor(15547.5459, grad_fn=<AddBackward0>)\n","tensor(19143.4883, grad_fn=<SumBackward0>)\n","tensor(-3199.6768, grad_fn=<SubBackward0>)\n","18\n","tensor(12893.4824, grad_fn=<AddBackward0>)\n","tensor(18782.8516, grad_fn=<SumBackward0>)\n","tensor(-2654.0635, grad_fn=<SubBackward0>)\n","19\n","tensor(10686.9111, grad_fn=<AddBackward0>)\n","tensor(18478.3867, grad_fn=<SumBackward0>)\n","tensor(-2206.5713, grad_fn=<SubBackward0>)\n","20\n","tensor(8855.2207, grad_fn=<AddBackward0>)\n","tensor(18240.4355, grad_fn=<SumBackward0>)\n","tensor(-1831.6904, grad_fn=<SubBackward0>)\n","21\n","tensor(7338.7588, grad_fn=<AddBackward0>)\n","tensor(18079.7227, grad_fn=<SumBackward0>)\n","tensor(-1516.4619, grad_fn=<SubBackward0>)\n","22\n","tensor(6085.8818, grad_fn=<AddBackward0>)\n","tensor(17998.3242, grad_fn=<SumBackward0>)\n","tensor(-1252.8770, grad_fn=<SubBackward0>)\n","23\n","tensor(5052.1533, grad_fn=<AddBackward0>)\n","tensor(17985.2266, grad_fn=<SumBackward0>)\n","tensor(-1033.7285, grad_fn=<SubBackward0>)\n","24\n","tensor(4200.0117, grad_fn=<AddBackward0>)\n","tensor(18019.7227, grad_fn=<SumBackward0>)\n","tensor(-852.1416, grad_fn=<SubBackward0>)\n","25\n","tensor(3498.0857, grad_fn=<AddBackward0>)\n","tensor(18078.5391, grad_fn=<SumBackward0>)\n","tensor(-701.9260, grad_fn=<SubBackward0>)\n","26\n","tensor(2920.3987, grad_fn=<AddBackward0>)\n","tensor(18141.0469, grad_fn=<SumBackward0>)\n","tensor(-577.6870, grad_fn=<SubBackward0>)\n","27\n","tensor(2445.6475, grad_fn=<AddBackward0>)\n","tensor(18194.2695, grad_fn=<SumBackward0>)\n","tensor(-474.7512, grad_fn=<SubBackward0>)\n","28\n","tensor(2056.4204, grad_fn=<AddBackward0>)\n","tensor(18233.1406, grad_fn=<SumBackward0>)\n","tensor(-389.2271, grad_fn=<SubBackward0>)\n","29\n","tensor(1738.3423, grad_fn=<AddBackward0>)\n","tensor(18258.8984, grad_fn=<SumBackward0>)\n","tensor(-318.0781, grad_fn=<SubBackward0>)\n","30\n","tensor(1479.3463, grad_fn=<AddBackward0>)\n","tensor(18276.0449, grad_fn=<SumBackward0>)\n","tensor(-258.9960, grad_fn=<SubBackward0>)\n","31\n","tensor(1269.1750, grad_fn=<AddBackward0>)\n","tensor(18289.7695, grad_fn=<SumBackward0>)\n","tensor(-210.1713, grad_fn=<SubBackward0>)\n","32\n","tensor(1099.1154, grad_fn=<AddBackward0>)\n","tensor(18303.8633, grad_fn=<SumBackward0>)\n","tensor(-170.0597, grad_fn=<SubBackward0>)\n","33\n","tensor(961.8283, grad_fn=<AddBackward0>)\n","tensor(18320.3984, grad_fn=<SumBackward0>)\n","tensor(-137.2870, grad_fn=<SubBackward0>)\n","34\n","tensor(851.1887, grad_fn=<AddBackward0>)\n","tensor(18339.6680, grad_fn=<SumBackward0>)\n","tensor(-110.6396, grad_fn=<SubBackward0>)\n","35\n","tensor(762.1470, grad_fn=<AddBackward0>)\n","tensor(18360.7852, grad_fn=<SumBackward0>)\n","tensor(-89.0416, grad_fn=<SubBackward0>)\n","36\n","tensor(690.5844, grad_fn=<AddBackward0>)\n","tensor(18382.4141, grad_fn=<SumBackward0>)\n","tensor(-71.5627, grad_fn=<SubBackward0>)\n","37\n","tensor(633.1692, grad_fn=<AddBackward0>)\n","tensor(18403.3555, grad_fn=<SumBackward0>)\n","tensor(-57.4152, grad_fn=<SubBackward0>)\n","38\n","tensor(587.1978, grad_fn=<AddBackward0>)\n","tensor(18422.6641, grad_fn=<SumBackward0>)\n","tensor(-45.9714, grad_fn=<SubBackward0>)\n","39\n","tensor(550.4530, grad_fn=<AddBackward0>)\n","tensor(18440.0234, grad_fn=<SumBackward0>)\n","tensor(-36.7448, grad_fn=<SubBackward0>)\n","40\n","tensor(521.1259, grad_fn=<AddBackward0>)\n","tensor(18454.9453, grad_fn=<SumBackward0>)\n","tensor(-29.3271, grad_fn=<SubBackward0>)\n","41\n","tensor(497.7337, grad_fn=<AddBackward0>)\n","tensor(18467.7578, grad_fn=<SumBackward0>)\n","tensor(-23.3921, grad_fn=<SubBackward0>)\n","42\n","tensor(479.0707, grad_fn=<AddBackward0>)\n","tensor(18478.6016, grad_fn=<SumBackward0>)\n","tensor(-18.6631, grad_fn=<SubBackward0>)\n","43\n","tensor(464.1664, grad_fn=<AddBackward0>)\n","tensor(18487.9375, grad_fn=<SumBackward0>)\n","tensor(-14.9042, grad_fn=<SubBackward0>)\n","44\n","tensor(452.2591, grad_fn=<AddBackward0>)\n","tensor(18495.7734, grad_fn=<SumBackward0>)\n","tensor(-11.9073, grad_fn=<SubBackward0>)\n","45\n","tensor(442.7566, grad_fn=<AddBackward0>)\n","tensor(18503.2617, grad_fn=<SumBackward0>)\n","tensor(-9.5025, grad_fn=<SubBackward0>)\n","46\n","tensor(435.1845, grad_fn=<AddBackward0>)\n","tensor(18510.2188, grad_fn=<SumBackward0>)\n","tensor(-7.5720, grad_fn=<SubBackward0>)\n","47\n","tensor(429.1591, grad_fn=<AddBackward0>)\n","tensor(18516.6406, grad_fn=<SumBackward0>)\n","tensor(-6.0255, grad_fn=<SubBackward0>)\n","48\n","tensor(424.3655, grad_fn=<AddBackward0>)\n","tensor(18522.5234, grad_fn=<SumBackward0>)\n","tensor(-4.7936, grad_fn=<SubBackward0>)\n","49\n","tensor(420.5490, grad_fn=<AddBackward0>)\n","tensor(18527.8359, grad_fn=<SumBackward0>)\n","tensor(-3.8165, grad_fn=<SubBackward0>)\n","50\n","tensor(417.5146, grad_fn=<AddBackward0>)\n","tensor(18532.5938, grad_fn=<SumBackward0>)\n","tensor(-3.0344, grad_fn=<SubBackward0>)\n","51\n","tensor(415.1062, grad_fn=<AddBackward0>)\n","tensor(18536.9102, grad_fn=<SumBackward0>)\n","tensor(-2.4084, grad_fn=<SubBackward0>)\n","52\n","tensor(413.1923, grad_fn=<AddBackward0>)\n","tensor(18540.3887, grad_fn=<SumBackward0>)\n","tensor(-1.9139, grad_fn=<SubBackward0>)\n","53\n","tensor(411.6642, grad_fn=<AddBackward0>)\n","tensor(18543.7715, grad_fn=<SumBackward0>)\n","tensor(-1.5281, grad_fn=<SubBackward0>)\n","54\n","tensor(410.4401, grad_fn=<AddBackward0>)\n","tensor(18546.6406, grad_fn=<SumBackward0>)\n","tensor(-1.2242, grad_fn=<SubBackward0>)\n","55\n","tensor(409.4629, grad_fn=<AddBackward0>)\n","tensor(18549.2773, grad_fn=<SumBackward0>)\n","tensor(-0.9772, grad_fn=<SubBackward0>)\n","56\n","tensor(408.6836, grad_fn=<AddBackward0>)\n","tensor(18551.4844, grad_fn=<SumBackward0>)\n","tensor(-0.7793, grad_fn=<SubBackward0>)\n","57\n","tensor(408.0714, grad_fn=<AddBackward0>)\n","tensor(18553.6016, grad_fn=<SumBackward0>)\n","tensor(-0.6122, grad_fn=<SubBackward0>)\n","58\n","tensor(407.5975, grad_fn=<AddBackward0>)\n","tensor(18555.2227, grad_fn=<SumBackward0>)\n","tensor(-0.4739, grad_fn=<SubBackward0>)\n","59\n","tensor(407.2275, grad_fn=<AddBackward0>)\n","tensor(18556.8516, grad_fn=<SumBackward0>)\n","tensor(-0.3700, grad_fn=<SubBackward0>)\n","60\n","tensor(406.9361, grad_fn=<AddBackward0>)\n","tensor(18558.2910, grad_fn=<SumBackward0>)\n","tensor(-0.2914, grad_fn=<SubBackward0>)\n","61\n","tensor(406.7025, grad_fn=<AddBackward0>)\n","tensor(18559.5879, grad_fn=<SumBackward0>)\n","tensor(-0.2336, grad_fn=<SubBackward0>)\n","62\n","tensor(406.5127, grad_fn=<AddBackward0>)\n","tensor(18560.5781, grad_fn=<SumBackward0>)\n","tensor(-0.1898, grad_fn=<SubBackward0>)\n","63\n","tensor(406.3765, grad_fn=<AddBackward0>)\n","tensor(18561.5000, grad_fn=<SumBackward0>)\n","tensor(-0.1362, grad_fn=<SubBackward0>)\n","64\n","tensor(406.2813, grad_fn=<AddBackward0>)\n","tensor(18561.9375, grad_fn=<SumBackward0>)\n","tensor(-0.0952, grad_fn=<SubBackward0>)\n","65\n","tensor(406.2083, grad_fn=<AddBackward0>)\n","tensor(18562.7207, grad_fn=<SumBackward0>)\n","tensor(-0.0730, grad_fn=<SubBackward0>)\n","66\n","tensor(406.1508, grad_fn=<AddBackward0>)\n","tensor(18563.5586, grad_fn=<SumBackward0>)\n","tensor(-0.0575, grad_fn=<SubBackward0>)\n","67\n","tensor(406.1092, grad_fn=<AddBackward0>)\n","tensor(18564.3477, grad_fn=<SumBackward0>)\n","tensor(-0.0416, grad_fn=<SubBackward0>)\n","68\n","tensor(406.0766, grad_fn=<AddBackward0>)\n","tensor(18564.8145, grad_fn=<SumBackward0>)\n","tensor(-0.0326, grad_fn=<SubBackward0>)\n","69\n","tensor(406.0576, grad_fn=<AddBackward0>)\n","tensor(18565.2344, grad_fn=<SumBackward0>)\n","tensor(-0.0190, grad_fn=<SubBackward0>)\n","70\n","tensor(406.0487, grad_fn=<AddBackward0>)\n","tensor(18565.5859, grad_fn=<SumBackward0>)\n","tensor(-0.0089, grad_fn=<SubBackward0>)\n","71\n","tensor(406.0458, grad_fn=<AddBackward0>)\n","tensor(18566.1055, grad_fn=<SumBackward0>)\n","tensor(-0.0029, grad_fn=<SubBackward0>)\n","72\n","tensor(406.0471, grad_fn=<AddBackward0>)\n","tensor(18566.1250, grad_fn=<SumBackward0>)\n","tensor(0.0013, grad_fn=<SubBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mr5cWP1gs8uV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0cCv3xetElY","colab_type":"code","outputId":"9eddce56-32f0-4890-eb17-30b3ea5114c5","executionInfo":{"status":"error","timestamp":1583397463486,"user_tz":0,"elapsed":1223,"user":{"displayName":"Stefan Brugger","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2hD3BccYoCZ1sg2Zmk5k0vgGm225f9Eq4B84cz1o=s64","userId":"09745208683004655373"}},"colab":{"base_uri":"https://localhost:8080/","height":163}},"source":["a.Sigma[2]"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1cf543d4da98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"]}]},{"cell_type":"code","metadata":{"id":"CVpzXQIPbEB5","colab_type":"code","colab":{}},"source":["import math \n","import numpy as np\n","from torch.nn import functional as F\n","from torch.nn import ModuleList\n","from torch.autograd import Variable, Function\n","from torch.nn import Linear, Module, LSTM, Parameter, BatchNorm2d, Conv2d, ConvTranspose2d, Softmax, RNN, RNNBase, RNNCell, RNNCellBase\n","from torch import zeros,zeros_like, ones_like, cat, ByteTensor, FloatTensor, rand, log, sigmoid\n","from torch import add,tanh,squeeze,Tensor,float,stack, argmax\n","from torch import max as torchmax\n","from torch import min as torchmin\n","from torch.autograd import Variable\n","from torch import cuda, no_grad, save, load, cat, zeros\n","from torch.optim import Adam\n","import torch \n","\n","class trainer(object):\n","\tdef __init__(self,p,model):\n","\t\tself.p = p\n","\t\tself.model = model\n","\t\tself.optimizer = Adam(self.model.parameters(), lr=self.model.p['lr'], weight_decay=1e-5)\n","\n","\n","#\tdef train:\n","\n","\n","\n","class pc_conv_layer(Module):\n","\tdef __init__(self,p,l):\n","\t\tsuper(pc_conv_layer, self).__init__()\n","\t\t#basics\n","\t\tself.p = p\n","\t\tself.l = l\n","\t\tself.dim = p['ldim'][l]\n","\t\tself.bs = p['batch_size']\n","\t\tself.imdim = p['imdim'][l]\n","\t\tself.dt = 1/p['inf_iter'] # integration step based on n interations\n","\n","\t\t# Inference Parameters\n","\t\tself.phi = torch.nn.Parameter(torch.rand([self.bs, self.dim * self.imdim * self.imdim]),requires_grad=True) \n","\n","\t\t# Learning parameters\n","\t\t#self.conv = Conv2d(p['ldim'][l], p['ldim'][l+1], p['nf'][l], padding=1)\n","\t\tself.conv_trans = ConvTranspose2d(p['ldim'][l], p['ldim'][l-1], p['nf'][l], padding=1)\n","\t\tself.Sigma = torch.nn.Parameter(torch.diag(torch.ones(self.dim * self.imdim * self.imdim)).unsqueeze(0).repeat(self.bs,1,1),requires_grad=True)\n","\n","\t\t# optimizer\n","\t\tself.optimizer = Adam(self.parameters(), lr=self.p['lr'], weight_decay=1e-5)\n","\n","\n","\tdef loss(self):\n","\n","\t\t# g(phi,Theta) = Theta*h(phi) = conv_trans(h(phi))\n","\t\t# hi_above are already in correct form\n","\t\tself.F = (torch.sum(0.5*(\t\n","\t\t\t\t\t- torch.logdet(self.Sigma)\n","\t\t\t\t\t- torch.matmul(\n","\t\t\t\t\t\ttorch.matmul(\n","\t\t\t\t\t\t\t(self.phi - self.phi_above).unsqueeze(1),\n","\t\t\t\t\t\t\ttorch.inverse(self.Sigma)\n","\t\t\t\t\t\t),\n","\t\t\t\t\t\t(self.phi - self.phi_above).unsqueeze(2)\n","\t\t\t\t\t)\n","\t\t\t\t\t- torch.logdet(self.Sigma_below) \n","\t\t\t\t\t- torch.squeeze(torch.matmul(\n","\t\t\t\t\t\ttorch.matmul(\t\t\t\t\t\t\n","\t\t\t\t\t\t\t(self.u - (self.conv_trans(self.phi.view(self.bs, self.dim, self.imdim, self.imdim))).view(self.bs,-1)).unsqueeze(1),#(torch.transpose(self.uu_gpt,1,2)),   \n","\t\t\t\t\t\t\ttorch.inverse(self.Sigma_below)\t\t\t\t# works for batch!\n","\t\t\t\t\t\t),\n","\t\t\t\t\t\t(self.u - (self.conv_trans(self.phi.view(self.bs, self.dim, self.imdim, self.imdim))).view(self.bs,-1)).unsqueeze(2),#(torch.transpose(self.uu_gpt,1,2)),   \n","\t\t\t\t\t))\n","\t\t\t\t)))\n","\n","\tdef inference(self):\n","\t\t# reset activities prior to starting (or not)\n","\t\t# certainly need to reset gradients\n","\n","\t\t# need grads for theta*h'(e); that said for now the weights don't need to be differentiated..\n","\t\t# NB h(vi) depends only on vi\n","\n","\t\tself.conv_trans.weight.requires_grad = False \n","\t\tself.conv_trans.bias.requires_grad = False\n","\t\tself.Sigma.requires_grad = False\n","\t\tself.phi.requires_grad = True\n","\n","\t\tself.optimizer.zero_grad()\n","\t\tself.loss()\n","\t\tself.F.backward()\n","\t\tself.optimizer.step()\n","\n","\t\t#self.total_loss += self.F.item()\n","\n","\t\t# what do i want to get out to pass to other layers\n","\t\t# theta*h'(e)\n","\n","\tdef forward(self, phi_above, u, Sigma_below):  \n","\t\tself.phi_above = phi_above.view(self.bs,-1)\n","\t\tself.Sigma_below = Sigma_below\n","\t\tself.u = u\n","\t\tself.inference()\n","\n","\t\t# outputs to send to adjacent layers\n","\t\t# e and u have now been updated by Adam\n","\n","\t\t#return self.u, self.conv(e)\n","\n","\t\t# need to add in batch norm\n","\t\t# need to be able to turn grads on and off\n","\t\t# eventually will want to incorporate this into one step for all layers, then propogate updated values\n","\t\t# so just want one iteration in inference?\n","\t\t# so have training iteration outside this class?"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYY2WAXI84p5","colab_type":"code","colab":{}},"source":["p = dict()\n","p['ldim'] = dict()\n","p['ldim'][1] = 10\n","p['ldim'][2] = 5\n","p['nf'] = dict()\n","p['nf'][2] = 3\n","p['inf_iter'] = 20\n","p['batch_size'] = 5\n","p['imdim'] = dict()\n","p['imdim'][1] = 15\n","p['imdim'][2] = 15\n","\n","p['lr'] = 0.0005\n","a = pc_conv_layer(p,2)\n","#batch_size, number_of_kernels, w, h].\n","phi_above = torch.rand(p['batch_size'],p['ldim'][2],p['imdim'][2],p['imdim'][2])\n","u = torch.rand(p['batch_size'],p['ldim'][1]*p['imdim'][1]*p['imdim'][1])\n","Sigma_below = torch.diag(torch.ones(p['ldim'][1] * p['imdim'][1] * p['imdim'][1])).unsqueeze(0).repeat(p['batch_size'],1,1)\n","a(phi_above,u,Sigma_below)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rsmX5QJR_z2s","colab_type":"code","outputId":"3121625b-d012-411b-96bd-b3e55f165052","executionInfo":{"status":"ok","timestamp":1582930420128,"user_tz":0,"elapsed":3208,"user":{"displayName":"Stefan Brugger","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANFCBfedBoHUWqNZvsqCls5RVp-zxycAOvMjpyZos=s64","userId":"09745208683004655373"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["a.F"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-12571.1055, grad_fn=<SumBackward0>)"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"qrdl-Y4e7avp","colab_type":"code","outputId":"abd40880-3a95-43e3-d49c-d027a1b7a1e9","executionInfo":{"status":"ok","timestamp":1574114212418,"user_tz":0,"elapsed":8026,"user":{"displayName":"Stefan Brugger","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANFCBfedBoHUWqNZvsqCls5RVp-zxycAOvMjpyZos=s64","userId":"09745208683004655373"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["% cd /content/drive/My\\ Drive/vae_prednet/cocoapi\n","!pip install kornia\n","#!curl https://sdk.cloud.google.com | bash\n","#!git clone https://github.com/cocodataset/cocoapi.git"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/vae_prednet/cocoapi\n","Collecting kornia\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/05/4adc0140932d37ab1ff02f3a88c3362d5d31b999936bb3af651f641e1295/kornia-0.1.4.post2-py2.py3-none-any.whl (114kB)\n","\u001b[K     |████████████████████████████████| 122kB 6.5MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from kornia) (1.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->kornia) (1.17.4)\n","Installing collected packages: kornia\n","Successfully installed kornia-0.1.4.post2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YKSKq0pxPFKa","colab_type":"code","outputId":"dd662b4e-2112-4243-e40f-f05d1ad2b64e","executionInfo":{"status":"ok","timestamp":1574114568502,"user_tz":0,"elapsed":151304,"user":{"displayName":"Stefan Brugger","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANFCBfedBoHUWqNZvsqCls5RVp-zxycAOvMjpyZos=s64","userId":"09745208683004655373"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["!pwd\n","!gsutil -m rsync gs://images.cocodataset.org/train2017 train"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/vae_prednet/cocoapi\n","Building synchronization state...\n","At source listing 10000...\n","At source listing 20000...\n","At source listing 30000...\n","At source listing 40000...\n","Caught non-retryable exception while listing file://train: [Errno 5] Input/output error: 'train'\n","At source listing 50000...\n","At source listing 60000...\n","At source listing 70000...\n","At source listing 80000...\n","At source listing 90000...\n","At source listing 100000...\n","At source listing 110000...\n","CommandException: Caught non-retryable exception - aborting rsync\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0_HDzc8nRfwn","colab_type":"code","outputId":"d75e1695-32d3-41b6-c6f1-224541d4f157","executionInfo":{"status":"ok","timestamp":1574093347406,"user_tz":0,"elapsed":1809,"user":{"displayName":"Stefan Brugger","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANFCBfedBoHUWqNZvsqCls5RVp-zxycAOvMjpyZos=s64","userId":"09745208683004655373"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/vae_prednet/cocoapi\n","/content/drive/My Drive/vae_prednet/cocoapi\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j16Cd87t7qkq","colab_type":"code","outputId":"a21908cb-a8f2-4810-c5e5-e04822ec518b","executionInfo":{"status":"ok","timestamp":1572391684358,"user_tz":0,"elapsed":30244,"user":{"displayName":"Stefan Brugger","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANFCBfedBoHUWqNZvsqCls5RVp-zxycAOvMjpyZos=s64","userId":"09745208683004655373"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python main.py -m stl10_patch.yaml"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2019-10-31:23:13:02,488 INFO     [main.py:25] Namespace(config='stl10_patch.yaml')\n","2019-10-31:23:13:02,491 INFO     [main.py:39] Training\n","2019-10-31:23:13:02,491 INFO     [main.py:40] Reading permutation : 0 of 1\n","{'b': 200,\n"," 'beta': 10.0,\n"," 'conv': True,\n"," 'dataset': 'stl10',\n"," 'dynamic': False,\n"," 'e': 25000,\n"," 'early_stopping': True,\n"," 'elbo_loss': True,\n"," 'enc_h': [100, 600],\n"," 'enc_temp': 0.67,\n"," 'err_noise': True,\n"," 'exp_name': 'stl10_patch',\n"," 'foveate': False,\n"," 'generate_data': False,\n"," 'gpu': True,\n"," 'h_label': '100',\n"," 'imdim': (1, 7, 7),\n"," 'interactive': False,\n"," 'layers': 1,\n"," 'lr': 0.0005,\n"," 'model_name': 'l1_stl10_pnt0_vae1_normal_z75_h100_c100000_b10_ld100_elboTrue',\n"," 'n_actions': 2,\n"," 'nz_con': [65, 0, 0],\n"," 'nz_dis': [[10], 0, 0],\n"," 'patience': 5,\n"," 'plot_iter': 500,\n"," 'prednet': False,\n"," 'rotating': False,\n"," 'sb_patch_size': 7,\n"," 'sequences': False,\n"," 'train_fx': False,\n"," 'train_gx': True,\n"," 'use_lstm': False,\n"," 'vae': True,\n"," 'x_dist': 'normal',\n"," 'z_con_capacity': [[0.0, 10.0, 100000, 100.0]],\n"," 'z_dim': [75],\n"," 'z_dis_capacity': [[0.0, 10.0, 100000, 100.0]],\n"," 'z_dist': 'normal',\n"," 'z_label': '75'}\n","2019-10-31:23:13:04,787 INFO     [main.py:63] Training Observation Model\n","Files already downloaded and verified\n","2019-10-31:23:13:27,694 INFO     [trainer.py:576] \n"," Training Observation Model \n"," \n","2019-10-31:23:13:27,695 INFO     [trainer.py:577] Model Overview: \n"," <bound method Module.parameters of ObservationVAE(\n","  (mse): MSELoss()\n","  (prior_dist): Normal (0.000, 1.000)\n","  (q_dist): Normal (0.000, 1.000)\n","  (x_dist): Normal (0.000, 1.000)\n","  (cat_dist): Gumbel()\n","  (f_enc): STL10_patch_ConvEncoder(\n","    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n","    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n","    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (fc1): Linear(in_features=128, out_features=100, bias=True)\n","    (fc_zp): Linear(in_features=100, out_features=130, bias=True)\n","    (fc_alphas): ModuleList(\n","      (0): Linear(in_features=100, out_features=10, bias=True)\n","    )\n","  )\n","  (g_dec): STL10_patch_ConvDecoder(\n","    (fc1): Linear(in_features=75, out_features=100, bias=True)\n","    (fc2): Linear(in_features=100, out_features=128, bias=True)\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (dec1): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (dec2): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n","    (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (dec3): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1))\n","  )\n",")> \n","\n","2019-10-31:23:13:27,696 INFO     [trainer.py:580] Trainable Params 233,681 \n","\n","2019-10-31:23:13:27,696 INFO     [trainer.py:581] Non-Trainable Params 0 \n","\n","2019-10-31:23:13:27,696 INFO     [trainer.py:586]  Training Epoch 1 of 25000 \n","2019-10-31:23:13:30,138 INFO     [trainer.py:272] Mean Epoch Loss - 68.28029951171875\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ObservationVAE. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MSELoss. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Normal. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Gumbel. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type STL10_patch_ConvEncoder. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type STL10_patch_ConvDecoder. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ConvTranspose2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","2019-10-31:23:14:18,232 INFO     [trainer.py:586]  Training Epoch 2 of 25000 \n","2019-10-31:23:14:20,486 INFO     [trainer.py:272] Mean Epoch Loss - 21.777621484375\n","2019-10-31:23:14:20,607 INFO     [trainer.py:586]  Training Epoch 3 of 25000 \n","2019-10-31:23:14:22,819 INFO     [trainer.py:272] Mean Epoch Loss - 13.559031298828126\n","2019-10-31:23:14:22,953 INFO     [trainer.py:586]  Training Epoch 4 of 25000 \n","2019-10-31:23:14:25,200 INFO     [trainer.py:272] Mean Epoch Loss - 8.854866064453125\n","2019-10-31:23:14:25,329 INFO     [trainer.py:586]  Training Epoch 5 of 25000 \n","2019-10-31:23:14:27,562 INFO     [trainer.py:272] Mean Epoch Loss - 5.8206505126953125\n","2019-10-31:23:14:27,691 INFO     [trainer.py:586]  Training Epoch 6 of 25000 \n","2019-10-31:23:14:29,941 INFO     [trainer.py:272] Mean Epoch Loss - 4.051706274414062\n","2019-10-31:23:14:30,79 INFO     [trainer.py:586]  Training Epoch 7 of 25000 \n","2019-10-31:23:14:32,360 INFO     [trainer.py:272] Mean Epoch Loss - 3.318530065917969\n","2019-10-31:23:14:32,486 INFO     [trainer.py:586]  Training Epoch 8 of 25000 \n","2019-10-31:23:14:34,748 INFO     [trainer.py:272] Mean Epoch Loss - 2.893580908203125\n","2019-10-31:23:14:34,892 INFO     [trainer.py:586]  Training Epoch 9 of 25000 \n","2019-10-31:23:14:37,160 INFO     [trainer.py:272] Mean Epoch Loss - 2.690379864501953\n","2019-10-31:23:14:37,298 INFO     [trainer.py:586]  Training Epoch 10 of 25000 \n","2019-10-31:23:14:39,506 INFO     [trainer.py:272] Mean Epoch Loss - 2.575815185546875\n","2019-10-31:23:14:39,630 INFO     [trainer.py:586]  Training Epoch 11 of 25000 \n","2019-10-31:23:14:41,861 INFO     [trainer.py:272] Mean Epoch Loss - 2.5018449279785155\n","2019-10-31:23:14:41,984 INFO     [trainer.py:586]  Training Epoch 12 of 25000 \n","2019-10-31:23:14:44,227 INFO     [trainer.py:272] Mean Epoch Loss - 2.400950067138672\n","2019-10-31:23:14:44,361 INFO     [trainer.py:586]  Training Epoch 13 of 25000 \n","2019-10-31:23:14:46,619 INFO     [trainer.py:272] Mean Epoch Loss - 2.331043176269531\n","2019-10-31:23:14:46,758 INFO     [trainer.py:586]  Training Epoch 14 of 25000 \n","2019-10-31:23:14:49,32 INFO     [trainer.py:272] Mean Epoch Loss - 2.2709110412597657\n","2019-10-31:23:14:49,160 INFO     [trainer.py:586]  Training Epoch 15 of 25000 \n","2019-10-31:23:14:51,400 INFO     [trainer.py:272] Mean Epoch Loss - 2.2413900634765627\n","2019-10-31:23:14:51,518 INFO     [trainer.py:586]  Training Epoch 16 of 25000 \n","2019-10-31:23:14:53,779 INFO     [trainer.py:272] Mean Epoch Loss - 2.278131848144531\n","2019-10-31:23:14:53,908 INFO     [trainer.py:586]  Training Epoch 17 of 25000 \n","2019-10-31:23:14:56,150 INFO     [trainer.py:272] Mean Epoch Loss - 2.2481508728027344\n","2019-10-31:23:14:56,275 INFO     [trainer.py:586]  Training Epoch 18 of 25000 \n","2019-10-31:23:14:58,563 INFO     [trainer.py:272] Mean Epoch Loss - 2.1883367065429686\n","2019-10-31:23:14:58,687 INFO     [trainer.py:586]  Training Epoch 19 of 25000 \n","2019-10-31:23:15:00,944 INFO     [trainer.py:272] Mean Epoch Loss - 2.188013348388672\n","2019-10-31:23:15:01,74 INFO     [trainer.py:586]  Training Epoch 20 of 25000 \n","2019-10-31:23:15:03,356 INFO     [trainer.py:272] Mean Epoch Loss - 2.0828146118164064\n","2019-10-31:23:15:03,480 INFO     [trainer.py:586]  Training Epoch 21 of 25000 \n","2019-10-31:23:15:05,763 INFO     [trainer.py:272] Mean Epoch Loss - 2.1293104736328123\n","2019-10-31:23:15:05,885 INFO     [trainer.py:586]  Training Epoch 22 of 25000 \n","2019-10-31:23:15:08,133 INFO     [trainer.py:272] Mean Epoch Loss - 2.1016546813964845\n","2019-10-31:23:15:08,263 INFO     [trainer.py:586]  Training Epoch 23 of 25000 \n","2019-10-31:23:15:10,499 INFO     [trainer.py:272] Mean Epoch Loss - 2.1068631896972656\n","2019-10-31:23:15:10,628 INFO     [trainer.py:586]  Training Epoch 24 of 25000 \n","2019-10-31:23:15:12,881 INFO     [trainer.py:272] Mean Epoch Loss - 2.0704123962402345\n","2019-10-31:23:15:13,11 INFO     [trainer.py:586]  Training Epoch 25 of 25000 \n","2019-10-31:23:15:15,288 INFO     [trainer.py:272] Mean Epoch Loss - 2.070953515625\n","2019-10-31:23:15:15,418 INFO     [trainer.py:586]  Training Epoch 26 of 25000 \n","2019-10-31:23:15:17,687 INFO     [trainer.py:272] Mean Epoch Loss - 2.099590167236328\n","2019-10-31:23:15:17,826 INFO     [trainer.py:586]  Training Epoch 27 of 25000 \n","2019-10-31:23:15:20,90 INFO     [trainer.py:272] Mean Epoch Loss - 1.9955972473144532\n","2019-10-31:23:15:20,227 INFO     [trainer.py:586]  Training Epoch 28 of 25000 \n","2019-10-31:23:15:22,509 INFO     [trainer.py:272] Mean Epoch Loss - 2.0060099243164062\n","2019-10-31:23:15:22,638 INFO     [trainer.py:586]  Training Epoch 29 of 25000 \n"],"name":"stdout"}]}]}